{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spooky Author.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOMmeEV55COCgGeaVXjS1Gn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arebs23/Spooky-Author-identification/blob/main/Spooky_Author.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp7OBEHwTO6C"
      },
      "source": [
        "This is a project on spooky author identification with traditional ML and deep learning approach. The data is available on Kaggle.  <br><br>\n",
        "Kaggle Competition: <br>\n",
        "https://www.kaggle.com/c/spooky-author-identification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVGOCWGdc18b",
        "outputId": "726880d7-3184-42bb-c34d-7110104dff39"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition,model_selection,metrics,pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from keras.layers import GlobalMaxPool1D, Conv1D, MaxPool1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.callbacks import EarlyStopping\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhGBHbVWkmtf",
        "outputId": "a12f01ba-d13c-4f6d-9f60-4609ed73f9ff"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = 'spooky-author-identification.zip'\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HWAA6Lfk3e8",
        "outputId": "ee57fa77-7414-42b9-9147-64bd387348e7"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = 'test.zip'\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBH3Clcnk5l_",
        "outputId": "249f0508-6d88-450a-a0c0-77c2d583c952"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = 'train.zip'\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzow-eARlE6Z"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "UFP-pYU0tbq7",
        "outputId": "d1ef16dc-9250-49f1-9af9-9431e05c1cdf"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "S3O2XBGCteSn",
        "outputId": "99fe4a10-f93d-4395-87cb-916b384930f5"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>And when they had broken down the frail door t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>While I was thinking how I should possibly man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>I am not sure to what limit his knowledge may ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text\n",
              "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
              "1  id24541  If a fire wanted fanning, it could readily be ...\n",
              "2  id00134  And when they had broken down the frail door t...\n",
              "3  id27757  While I was thinking how I should possibly man...\n",
              "4  id04081  I am not sure to what limit his knowledge may ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY2168hOthcv"
      },
      "source": [
        "def multiclass_logloss(actual,predicted, eps = 1e-15):\n",
        "  if len(actual.shape) == 1:\n",
        "    actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
        "    for i, val in enumerate(actual):\n",
        "      actual2[i, val] = 1\n",
        "    actual = actual2\n",
        "\n",
        "  \n",
        "  clip = np.clip(predicted, eps, 1 - eps)\n",
        "  rows = actual.shape[0]\n",
        "  vsota  = np.sum(actual * np.log(clip))\n",
        "  return -1.0/rows * vsota"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf3WpLIXu1BE"
      },
      "source": [
        "lbl_enc = preprocessing.LabelEncoder()\n",
        "y = lbl_enc.fit_transform(train.author.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95iwJLJbvbmj"
      },
      "source": [
        "x_train,x_valid,y_train,y_valid = train_test_split(train.text.values,y,stratify = y,random_state = 42,test_size = 0.1, shuffle  = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OZZM0ETv1AN",
        "outputId": "9cab3de4-03e5-4f1c-8778-ecbc3bcf9008"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17621,)\n",
            "(1958,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmWOlSKyv-Ow"
      },
      "source": [
        "tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode',\n",
        "                      analyzer='word',token_pattern=r'\\w{1,}',ngram_range=(1,3),use_idf=1, \n",
        "                      smooth_idf=1,sublinear_tf=1,stop_words = 'english')\n",
        "\n",
        "tfv.fit(list(x_train)+list(x_valid))\n",
        "x_train_tfv = tfv.transform(x_train)\n",
        "x_valid_tfv = tfv.transform(x_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUjvaazgyCKL",
        "outputId": "ff086dbd-5f3e-41cc-a2ec-175d4758c956"
      },
      "source": [
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(x_train_tfv, y_train)\n",
        "predictions = clf.predict_proba(x_valid_tfv)\n",
        "\n",
        "print(\"logloss: %0.3f\" % multiclass_logloss(y_valid,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m88jnvOI00lc",
        "outputId": "b2fb7f81-b0b4-441e-b18b-d862d1c441f7"
      },
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(x_train_tfv,y_train)\n",
        "predictions = clf.predict_proba(x_valid_tfv)\n",
        "\n",
        "print(\"logloss: %0.3f\" % multiclass_logloss(y_valid,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ31MJhQ1T0m"
      },
      "source": [
        "svd = decomposition.TruncatedSVD(n_components=120)\n",
        "svd.fit(x_train_tfv)\n",
        "x_train_svd = svd.transform(x_train_tfv)\n",
        "x_valid_svd = svd.transform(x_valid_tfv)\n",
        "\n",
        "\n",
        "scl = preprocessing.StandardScaler()\n",
        "scl.fit(x_train_svd)\n",
        "x_train_svd_scl = scl.transform(x_train_svd)\n",
        "x_valid_svd_scl = scl.transform(x_valid_svd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwrRB7_o2IhY",
        "outputId": "83dc498d-ef2b-46f7-9639-975605e72328"
      },
      "source": [
        "clf = SVC(C=1.0,probability=True)\n",
        "clf.fit(x_train_svd_scl,y_train)\n",
        "prediction = clf.predict_proba(x_valid_svd_scl)\n",
        "\n",
        "print(\"logloss: %0.3f\" % multiclass_logloss(y_valid,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8aCZSDo6X9t",
        "outputId": "ef0a3b5b-a4b8-4364-e174-d36b734863e0"
      },
      "source": [
        "clf = xgb.XGBClassifier(nthread=10)\n",
        "clf.fit(x_train_svd,y_train)\n",
        "predictions = clf.predict_proba(x_valid_svd)\n",
        "\n",
        "\n",
        "print(\"logloss: %0.3f\" % multiclass_logloss(y_valid,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5EEvWHz-Pan"
      },
      "source": [
        "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False,needs_proba=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asdNPpsc-nY_"
      },
      "source": [
        "svd = TruncatedSVD()\n",
        "\n",
        "scl =  preprocessing.StandardScaler()\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "clf = pipeline.Pipeline([('svd', svd),('scl',scl),('lr',lr_model)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "291WKLfK_rXJ"
      },
      "source": [
        "param_grid = {'svd__n_components':[120,180],\n",
        "              'lr__C':[0.1,1.0,10],'lr__penalty':['l1','l2']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_H1lD0BAJ4i",
        "outputId": "0b74f898-fb4b-4502-d003-7dc67731d32c"
      },
      "source": [
        "model = GridSearchCV(estimator = clf,param_grid=param_grid, \n",
        "                     scoring=mll_scorer,verbose=10,\n",
        "                     n_jobs = -1,iid = True,refit = True,cv=2)\n",
        "\n",
        "model.fit(x_train_tfv,y_train)\n",
        "\n",
        "print('best score: %0.3f' % model.best_score_)\n",
        "print('Best parameters set:')\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "  print(\"\\t%s: %r\" %(param_name, best_parameters[param_name]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   19.3s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   30.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   33.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   33.7s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best score: -0.739\n",
            "Best parameters set:\n",
            "\tlr__C: 0.1\n",
            "\tlr__penalty: 'l2'\n",
            "\tsvd__n_components: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdjYnrTRCTLz",
        "outputId": "6863e43a-bf30-49f6-c85b-810628f21425"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 16:37:36--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2021-05-12 16:37:37--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2021-05-12 16:37:37--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  5.26MB/s    in 6m 55s  \n",
            "\n",
            "2021-05-12 16:44:33 (5.00 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INZw6O-IInv_",
        "outputId": "84ad29f2-9e81-4fe3-d25c-278c7d286c09"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = 'glove.840B.300d.zip'\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPqMZH_xSgBN"
      },
      "source": [
        "### Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1Z_eqIFYQEg"
      },
      "source": [
        "def load_glove_index():\n",
        "  EMBEDDING_FILE = '/content/glove.840B.300d.txt'\n",
        "  def get_coefs(word, *arr):return word, np.asarray(arr, dtype = 'float32')[100:]\n",
        "  embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "  return embeddings_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fZOrZzWZcho",
        "outputId": "ddbc1eb7-e888-45a8-f026-00c2569139a5"
      },
      "source": [
        "embeddings_index = load_glove_index()\n",
        "print('Found %s word vectors' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2196016 word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fHn41D6fj8T"
      },
      "source": [
        "def sent2vec(s):\n",
        "  words  = str(s).lower()\n",
        "  words = word_tokenize(words)\n",
        "  words = [w for w in words if not w in stop_words]\n",
        "  words = [w for w in words if w.isalpha()]\n",
        "  M  = []\n",
        "  for w in words:\n",
        "    try:\n",
        "      M.append(embeddings_index[w])\n",
        "    except:\n",
        "      continue\n",
        "  \n",
        "  M = np.array(M)\n",
        "  v = M.sum(axis = 0)\n",
        "  if type(v) != np.ndarray:\n",
        "    return np.zeros(300)\n",
        "  return v / np.sqrt((v ** 2).sum())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-QMku9vOhUr"
      },
      "source": [
        "x_train_glove = [sent2vec(x) for x in tqdm(x_train)]\n",
        "x_valid_glove = [sent2vec(x) for x in tqdm(x_valid)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry2F2fHQhNe5"
      },
      "source": [
        "x_train_glove = np.array(x_train_glove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX-U8RhZjjLu"
      },
      "source": [
        "x_valid_glove = np.array(x_valid_glove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VpsyxsAjmGW",
        "outputId": "389bae08-1edf-42e6-bda5-ec2a9afc74d3"
      },
      "source": [
        "x_train_glove.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17621,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihnuUMCIqXlV",
        "outputId": "f4cf8d48-c294-4fe1-a2b5-2ad51377d3ce"
      },
      "source": [
        "x_train_tfv.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17621, 15102)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71tdsViqktXP"
      },
      "source": [
        "log_clf = LogisticRegression(C=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HH059j9h3ow"
      },
      "source": [
        "xgb_clf = xgb.XGBClassifier(nthread=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "YRDIFp4Jk91O",
        "outputId": "542ff2e9-71a0-4ffb-b440-7f34c6ba1c04"
      },
      "source": [
        "xgb_clf.fit(x_train_glove, y_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-af8e90e02da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "9xeTdT3dh6Oo",
        "outputId": "62b3120f-36a9-45c2-def4-8f1362cfd4c6"
      },
      "source": [
        "log_clf.fit(x_train_glove, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-bf021c4c2fe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ-0udTQkBsu"
      },
      "source": [
        "predictions = clf.predict_proba(x_valid_glove)\n",
        "print(\"logloss: %0.3f\" % multiclass_logloss(y_valid,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfAU8CFLntTb",
        "outputId": "27ea3ce0-7799-4c78-864e-8e1f1fb357a8"
      },
      "source": [
        "x_train_glove.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBwDUtDgnTaj"
      },
      "source": [
        "scl = preprocessing.StandardScaler()\n",
        "x_train_glove_scl = scl.fit_transform(x_train_glove)\n",
        "x_valid_glove_scl = scl.fit_transform(x_valid_glove)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXp6PD8IRP_i"
      },
      "source": [
        "# Let Try a Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmAgVd5rRd8b"
      },
      "source": [
        "### Preprocessing steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ9kETsrrMCM"
      },
      "source": [
        "token = text.Tokenizer()\n",
        "max_len = 70\n",
        "\n",
        "token.fit_on_texts(list(x_train)+list(x_valid))\n",
        "x_train_seq = token.texts_to_sequences(x_train)\n",
        "x_valid_seq = token.texts_to_sequences(x_valid)\n",
        "\n",
        "\n",
        "x_train_pad = sequence.pad_sequences(x_train_seq, maxlen=max_len)\n",
        "x_valid_pad = sequence.pad_sequences(x_valid_seq, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnuQ2f7UsN-2"
      },
      "source": [
        "word_index = token.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtPW6kV8sT8w",
        "outputId": "e115f855-d900-479a-fd22-fb02c766455f"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index)+1,200))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 25943/25943 [00:00<00:00, 322814.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJeWd59CvTcU"
      },
      "source": [
        "y_train_enc = np_utils.to_categorical(y_train)\n",
        "y_valid_enc =  np_utils.to_categorical(y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxsU0M_SR_BH"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAEdZfS-tXwa",
        "outputId": "6c20ecf2-48ed-464b-8ea6-326f35cfd5d1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index)+1,200,\n",
        "                    weights = [embedding_matrix],input_length = max_len,trainable = False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(100,dropout=0.3,recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024,activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer ='adam',metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAEuO7y2xNCk",
        "outputId": "f5164e52-61e9-47ed-92aa-9eb87a5ada4e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 70, 200)           5188800   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 70, 200)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               120400    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              103424    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 3075      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 6,465,299\n",
            "Trainable params: 1,276,499\n",
            "Non-trainable params: 5,188,800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztJxzqPpvNEo",
        "outputId": "f7daafe2-20ef-4fae-a69c-0bd64ba5256d"
      },
      "source": [
        "model.fit(x_train_pad,y_train_enc, batch_size = 512, epochs = 100,verbose = 1,validation_data = (x_valid_pad,y_valid_enc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "35/35 [==============================] - 18s 359ms/step - loss: 1.0898 - acc: 0.3952 - val_loss: 0.9334 - val_acc: 0.5807\n",
            "Epoch 2/100\n",
            "35/35 [==============================] - 12s 356ms/step - loss: 0.9422 - acc: 0.5564 - val_loss: 0.7859 - val_acc: 0.6742\n",
            "Epoch 3/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.8604 - acc: 0.6155 - val_loss: 0.7623 - val_acc: 0.6639\n",
            "Epoch 4/100\n",
            "35/35 [==============================] - 12s 342ms/step - loss: 0.8268 - acc: 0.6347 - val_loss: 0.7281 - val_acc: 0.7043\n",
            "Epoch 5/100\n",
            "35/35 [==============================] - 12s 352ms/step - loss: 0.7943 - acc: 0.6499 - val_loss: 0.7128 - val_acc: 0.7099\n",
            "Epoch 6/100\n",
            "35/35 [==============================] - 12s 342ms/step - loss: 0.7855 - acc: 0.6649 - val_loss: 0.6950 - val_acc: 0.7155\n",
            "Epoch 7/100\n",
            "35/35 [==============================] - 12s 348ms/step - loss: 0.7716 - acc: 0.6650 - val_loss: 0.6925 - val_acc: 0.7084\n",
            "Epoch 8/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.7587 - acc: 0.6671 - val_loss: 0.6817 - val_acc: 0.7145\n",
            "Epoch 9/100\n",
            "35/35 [==============================] - 12s 346ms/step - loss: 0.7356 - acc: 0.6870 - val_loss: 0.6708 - val_acc: 0.7263\n",
            "Epoch 10/100\n",
            "35/35 [==============================] - 12s 352ms/step - loss: 0.7096 - acc: 0.7039 - val_loss: 0.6579 - val_acc: 0.7344\n",
            "Epoch 11/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.7039 - acc: 0.7009 - val_loss: 0.6179 - val_acc: 0.7594\n",
            "Epoch 12/100\n",
            "35/35 [==============================] - 12s 341ms/step - loss: 0.6698 - acc: 0.7209 - val_loss: 0.6201 - val_acc: 0.7549\n",
            "Epoch 13/100\n",
            "35/35 [==============================] - 12s 346ms/step - loss: 0.6625 - acc: 0.7204 - val_loss: 0.6169 - val_acc: 0.7605\n",
            "Epoch 14/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.6331 - acc: 0.7370 - val_loss: 0.5917 - val_acc: 0.7763\n",
            "Epoch 15/100\n",
            "35/35 [==============================] - 12s 344ms/step - loss: 0.6314 - acc: 0.7392 - val_loss: 0.5912 - val_acc: 0.7661\n",
            "Epoch 16/100\n",
            "35/35 [==============================] - 12s 347ms/step - loss: 0.6146 - acc: 0.7433 - val_loss: 0.5824 - val_acc: 0.7804\n",
            "Epoch 17/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.6110 - acc: 0.7502 - val_loss: 0.5816 - val_acc: 0.7656\n",
            "Epoch 18/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.5832 - acc: 0.7555 - val_loss: 0.5746 - val_acc: 0.7686\n",
            "Epoch 19/100\n",
            "35/35 [==============================] - 12s 347ms/step - loss: 0.5810 - acc: 0.7636 - val_loss: 0.5770 - val_acc: 0.7661\n",
            "Epoch 20/100\n",
            "35/35 [==============================] - 12s 340ms/step - loss: 0.5736 - acc: 0.7628 - val_loss: 0.5574 - val_acc: 0.7886\n",
            "Epoch 21/100\n",
            "35/35 [==============================] - 12s 348ms/step - loss: 0.5647 - acc: 0.7665 - val_loss: 0.5715 - val_acc: 0.7702\n",
            "Epoch 22/100\n",
            "35/35 [==============================] - 12s 352ms/step - loss: 0.5663 - acc: 0.7654 - val_loss: 0.5445 - val_acc: 0.7870\n",
            "Epoch 23/100\n",
            "35/35 [==============================] - 13s 357ms/step - loss: 0.5353 - acc: 0.7827 - val_loss: 0.5430 - val_acc: 0.7845\n",
            "Epoch 24/100\n",
            "35/35 [==============================] - 13s 358ms/step - loss: 0.5483 - acc: 0.7810 - val_loss: 0.5438 - val_acc: 0.7804\n",
            "Epoch 25/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.5401 - acc: 0.7825 - val_loss: 0.5456 - val_acc: 0.7773\n",
            "Epoch 26/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.5482 - acc: 0.7751 - val_loss: 0.5318 - val_acc: 0.7886\n",
            "Epoch 27/100\n",
            "35/35 [==============================] - 12s 357ms/step - loss: 0.5249 - acc: 0.7830 - val_loss: 0.5296 - val_acc: 0.7901\n",
            "Epoch 28/100\n",
            "35/35 [==============================] - 12s 348ms/step - loss: 0.5148 - acc: 0.7899 - val_loss: 0.5343 - val_acc: 0.7916\n",
            "Epoch 29/100\n",
            "35/35 [==============================] - 12s 345ms/step - loss: 0.5100 - acc: 0.7922 - val_loss: 0.5282 - val_acc: 0.7947\n",
            "Epoch 30/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.5006 - acc: 0.7945 - val_loss: 0.5435 - val_acc: 0.7850\n",
            "Epoch 31/100\n",
            "35/35 [==============================] - 13s 358ms/step - loss: 0.5049 - acc: 0.7931 - val_loss: 0.5225 - val_acc: 0.7957\n",
            "Epoch 32/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.4845 - acc: 0.8034 - val_loss: 0.5239 - val_acc: 0.7967\n",
            "Epoch 33/100\n",
            "35/35 [==============================] - 12s 356ms/step - loss: 0.4780 - acc: 0.8088 - val_loss: 0.5383 - val_acc: 0.7829\n",
            "Epoch 34/100\n",
            "35/35 [==============================] - 12s 343ms/step - loss: 0.4728 - acc: 0.8104 - val_loss: 0.5161 - val_acc: 0.8013\n",
            "Epoch 35/100\n",
            "35/35 [==============================] - 12s 350ms/step - loss: 0.4837 - acc: 0.8022 - val_loss: 0.5357 - val_acc: 0.7937\n",
            "Epoch 36/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.4612 - acc: 0.8190 - val_loss: 0.5186 - val_acc: 0.7962\n",
            "Epoch 37/100\n",
            "35/35 [==============================] - 12s 343ms/step - loss: 0.4619 - acc: 0.8171 - val_loss: 0.5263 - val_acc: 0.7967\n",
            "Epoch 38/100\n",
            "35/35 [==============================] - 12s 343ms/step - loss: 0.4523 - acc: 0.8190 - val_loss: 0.5137 - val_acc: 0.7972\n",
            "Epoch 39/100\n",
            "35/35 [==============================] - 12s 345ms/step - loss: 0.4420 - acc: 0.8224 - val_loss: 0.5126 - val_acc: 0.8023\n",
            "Epoch 40/100\n",
            "35/35 [==============================] - 12s 351ms/step - loss: 0.4674 - acc: 0.8058 - val_loss: 0.5236 - val_acc: 0.8049\n",
            "Epoch 41/100\n",
            "35/35 [==============================] - 12s 347ms/step - loss: 0.4512 - acc: 0.8215 - val_loss: 0.5022 - val_acc: 0.7967\n",
            "Epoch 42/100\n",
            "35/35 [==============================] - 12s 344ms/step - loss: 0.4347 - acc: 0.8264 - val_loss: 0.5381 - val_acc: 0.8008\n",
            "Epoch 43/100\n",
            "35/35 [==============================] - 12s 345ms/step - loss: 0.4481 - acc: 0.8227 - val_loss: 0.5396 - val_acc: 0.7875\n",
            "Epoch 44/100\n",
            "35/35 [==============================] - 12s 345ms/step - loss: 0.4289 - acc: 0.8307 - val_loss: 0.5079 - val_acc: 0.8008\n",
            "Epoch 45/100\n",
            "35/35 [==============================] - 12s 345ms/step - loss: 0.4326 - acc: 0.8306 - val_loss: 0.5393 - val_acc: 0.7901\n",
            "Epoch 46/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.4319 - acc: 0.8290 - val_loss: 0.5119 - val_acc: 0.7998\n",
            "Epoch 47/100\n",
            "35/35 [==============================] - 12s 343ms/step - loss: 0.4327 - acc: 0.8299 - val_loss: 0.5180 - val_acc: 0.8039\n",
            "Epoch 48/100\n",
            "35/35 [==============================] - 12s 351ms/step - loss: 0.4249 - acc: 0.8329 - val_loss: 0.5536 - val_acc: 0.7978\n",
            "Epoch 49/100\n",
            "35/35 [==============================] - 13s 357ms/step - loss: 0.4234 - acc: 0.8301 - val_loss: 0.5531 - val_acc: 0.7962\n",
            "Epoch 50/100\n",
            "35/35 [==============================] - 12s 356ms/step - loss: 0.4042 - acc: 0.8386 - val_loss: 0.5034 - val_acc: 0.8008\n",
            "Epoch 51/100\n",
            "35/35 [==============================] - 12s 345ms/step - loss: 0.4171 - acc: 0.8346 - val_loss: 0.4978 - val_acc: 0.8044\n",
            "Epoch 52/100\n",
            "35/35 [==============================] - 12s 355ms/step - loss: 0.4000 - acc: 0.8423 - val_loss: 0.5302 - val_acc: 0.7952\n",
            "Epoch 53/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.3822 - acc: 0.8480 - val_loss: 0.5127 - val_acc: 0.7998\n",
            "Epoch 54/100\n",
            "35/35 [==============================] - 13s 357ms/step - loss: 0.4028 - acc: 0.8409 - val_loss: 0.5384 - val_acc: 0.7962\n",
            "Epoch 55/100\n",
            "35/35 [==============================] - 12s 348ms/step - loss: 0.3892 - acc: 0.8434 - val_loss: 0.5127 - val_acc: 0.8054\n",
            "Epoch 56/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.3914 - acc: 0.8446 - val_loss: 0.5458 - val_acc: 0.7988\n",
            "Epoch 57/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.3791 - acc: 0.8489 - val_loss: 0.5060 - val_acc: 0.8049\n",
            "Epoch 58/100\n",
            "35/35 [==============================] - 12s 348ms/step - loss: 0.3849 - acc: 0.8438 - val_loss: 0.5234 - val_acc: 0.7993\n",
            "Epoch 59/100\n",
            "35/35 [==============================] - 12s 344ms/step - loss: 0.3861 - acc: 0.8474 - val_loss: 0.5052 - val_acc: 0.8044\n",
            "Epoch 60/100\n",
            "35/35 [==============================] - 12s 352ms/step - loss: 0.3778 - acc: 0.8505 - val_loss: 0.5123 - val_acc: 0.8008\n",
            "Epoch 61/100\n",
            "35/35 [==============================] - 12s 346ms/step - loss: 0.3720 - acc: 0.8510 - val_loss: 0.5233 - val_acc: 0.7957\n",
            "Epoch 62/100\n",
            "35/35 [==============================] - 12s 351ms/step - loss: 0.3827 - acc: 0.8449 - val_loss: 0.5403 - val_acc: 0.7896\n",
            "Epoch 63/100\n",
            "35/35 [==============================] - 12s 351ms/step - loss: 0.3832 - acc: 0.8499 - val_loss: 0.5344 - val_acc: 0.8080\n",
            "Epoch 64/100\n",
            "35/35 [==============================] - 12s 351ms/step - loss: 0.3643 - acc: 0.8549 - val_loss: 0.5223 - val_acc: 0.8085\n",
            "Epoch 65/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.3611 - acc: 0.8582 - val_loss: 0.5186 - val_acc: 0.8059\n",
            "Epoch 66/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.3711 - acc: 0.8572 - val_loss: 0.5248 - val_acc: 0.7998\n",
            "Epoch 67/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.3647 - acc: 0.8573 - val_loss: 0.5176 - val_acc: 0.7947\n",
            "Epoch 68/100\n",
            "35/35 [==============================] - 12s 355ms/step - loss: 0.3512 - acc: 0.8592 - val_loss: 0.5352 - val_acc: 0.7993\n",
            "Epoch 69/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.3507 - acc: 0.8592 - val_loss: 0.5239 - val_acc: 0.8059\n",
            "Epoch 70/100\n",
            "35/35 [==============================] - 12s 355ms/step - loss: 0.3519 - acc: 0.8618 - val_loss: 0.5394 - val_acc: 0.7983\n",
            "Epoch 71/100\n",
            "35/35 [==============================] - 12s 344ms/step - loss: 0.3536 - acc: 0.8641 - val_loss: 0.5072 - val_acc: 0.8008\n",
            "Epoch 72/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.3550 - acc: 0.8614 - val_loss: 0.5644 - val_acc: 0.7978\n",
            "Epoch 73/100\n",
            "35/35 [==============================] - 12s 356ms/step - loss: 0.3456 - acc: 0.8613 - val_loss: 0.5214 - val_acc: 0.8018\n",
            "Epoch 74/100\n",
            "35/35 [==============================] - 12s 346ms/step - loss: 0.3461 - acc: 0.8669 - val_loss: 0.5474 - val_acc: 0.7998\n",
            "Epoch 75/100\n",
            "35/35 [==============================] - 12s 351ms/step - loss: 0.3518 - acc: 0.8623 - val_loss: 0.5398 - val_acc: 0.8044\n",
            "Epoch 76/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.3414 - acc: 0.8658 - val_loss: 0.5175 - val_acc: 0.8018\n",
            "Epoch 77/100\n",
            "35/35 [==============================] - 12s 350ms/step - loss: 0.3406 - acc: 0.8665 - val_loss: 0.5225 - val_acc: 0.8080\n",
            "Epoch 78/100\n",
            "35/35 [==============================] - 12s 357ms/step - loss: 0.3329 - acc: 0.8719 - val_loss: 0.5186 - val_acc: 0.8075\n",
            "Epoch 79/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.3472 - acc: 0.8646 - val_loss: 0.5268 - val_acc: 0.8095\n",
            "Epoch 80/100\n",
            "35/35 [==============================] - 12s 352ms/step - loss: 0.3427 - acc: 0.8687 - val_loss: 0.5440 - val_acc: 0.8039\n",
            "Epoch 81/100\n",
            "35/35 [==============================] - 12s 352ms/step - loss: 0.3434 - acc: 0.8653 - val_loss: 0.5499 - val_acc: 0.7998\n",
            "Epoch 82/100\n",
            "35/35 [==============================] - 12s 356ms/step - loss: 0.3366 - acc: 0.8676 - val_loss: 0.5489 - val_acc: 0.7962\n",
            "Epoch 83/100\n",
            "35/35 [==============================] - 13s 359ms/step - loss: 0.3418 - acc: 0.8666 - val_loss: 0.5341 - val_acc: 0.7988\n",
            "Epoch 84/100\n",
            "35/35 [==============================] - 13s 360ms/step - loss: 0.3211 - acc: 0.8716 - val_loss: 0.5479 - val_acc: 0.8029\n",
            "Epoch 85/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.3346 - acc: 0.8664 - val_loss: 0.5416 - val_acc: 0.8013\n",
            "Epoch 86/100\n",
            "35/35 [==============================] - 12s 357ms/step - loss: 0.3223 - acc: 0.8764 - val_loss: 0.5750 - val_acc: 0.7911\n",
            "Epoch 87/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.3166 - acc: 0.8750 - val_loss: 0.5281 - val_acc: 0.8003\n",
            "Epoch 88/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.3122 - acc: 0.8782 - val_loss: 0.5387 - val_acc: 0.8044\n",
            "Epoch 89/100\n",
            "35/35 [==============================] - 12s 348ms/step - loss: 0.3402 - acc: 0.8688 - val_loss: 0.5561 - val_acc: 0.8034\n",
            "Epoch 90/100\n",
            "35/35 [==============================] - 12s 355ms/step - loss: 0.3287 - acc: 0.8684 - val_loss: 0.5374 - val_acc: 0.8095\n",
            "Epoch 91/100\n",
            "35/35 [==============================] - 12s 346ms/step - loss: 0.3159 - acc: 0.8807 - val_loss: 0.5650 - val_acc: 0.8039\n",
            "Epoch 92/100\n",
            "35/35 [==============================] - 12s 344ms/step - loss: 0.3026 - acc: 0.8791 - val_loss: 0.5573 - val_acc: 0.7988\n",
            "Epoch 93/100\n",
            "35/35 [==============================] - 12s 350ms/step - loss: 0.3182 - acc: 0.8760 - val_loss: 0.5441 - val_acc: 0.8008\n",
            "Epoch 94/100\n",
            "35/35 [==============================] - 12s 352ms/step - loss: 0.3072 - acc: 0.8793 - val_loss: 0.5597 - val_acc: 0.8029\n",
            "Epoch 95/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.3102 - acc: 0.8832 - val_loss: 0.5566 - val_acc: 0.8029\n",
            "Epoch 96/100\n",
            "35/35 [==============================] - 12s 355ms/step - loss: 0.3068 - acc: 0.8828 - val_loss: 0.5580 - val_acc: 0.8003\n",
            "Epoch 97/100\n",
            "35/35 [==============================] - 12s 349ms/step - loss: 0.3203 - acc: 0.8764 - val_loss: 0.5452 - val_acc: 0.8049\n",
            "Epoch 98/100\n",
            "35/35 [==============================] - 12s 352ms/step - loss: 0.2983 - acc: 0.8871 - val_loss: 0.5407 - val_acc: 0.8034\n",
            "Epoch 99/100\n",
            "35/35 [==============================] - 12s 353ms/step - loss: 0.3057 - acc: 0.8808 - val_loss: 0.5468 - val_acc: 0.8110\n",
            "Epoch 100/100\n",
            "35/35 [==============================] - 12s 354ms/step - loss: 0.2931 - acc: 0.8843 - val_loss: 0.5664 - val_acc: 0.8023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f18206b9590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdQAX3lM3q3C"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "loss = history.history['loss']\n",
        "epochs = range(1,len(acc) + 1)\n",
        "plt.plot(epochs,acc,'bo',label = 'Training acc')\n",
        "plt.plot(epochs,acc,'b',label = 'validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs,loss,'bo',label = 'Training loss')\n",
        "plt.plot(epochs,val_loss,'b',label = 'validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckJzNyTc2Fw7"
      },
      "source": [
        "#save the model\n",
        "model.save_weights('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WOCz--AOwej"
      },
      "source": [
        "#load model\n",
        "model = load_model('model.h5')\n",
        "#evaluate on test dataset\n",
        "_,acc = model.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}